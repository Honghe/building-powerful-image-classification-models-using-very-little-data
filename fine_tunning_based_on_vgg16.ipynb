{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_6 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,097,665\n",
      "Trainable params: 2,097,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:79: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"se...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_6 (Sequential)    (None, 1)                 2097665   \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 9,177,089\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:122: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:122: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., epochs=50, validation_data=<keras_pre..., steps_per_epoch=125, validation_steps=800)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/125 [==============================] - 45s 361ms/step - loss: 0.4315 - acc: 0.8645 - val_loss: 0.3735 - val_acc: 0.8650\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 44s 354ms/step - loss: 0.2106 - acc: 0.9185 - val_loss: 0.3098 - val_acc: 0.8912\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 44s 353ms/step - loss: 0.1856 - acc: 0.9345 - val_loss: 0.3673 - val_acc: 0.8862\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 44s 351ms/step - loss: 0.1318 - acc: 0.9585 - val_loss: 0.3264 - val_acc: 0.8975\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 44s 351ms/step - loss: 0.1060 - acc: 0.9610 - val_loss: 0.3371 - val_acc: 0.8950\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 44s 349ms/step - loss: 0.0961 - acc: 0.9675 - val_loss: 0.4258 - val_acc: 0.8888\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 44s 353ms/step - loss: 0.0788 - acc: 0.9745 - val_loss: 0.3844 - val_acc: 0.9062\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 45s 356ms/step - loss: 0.0781 - acc: 0.9710 - val_loss: 0.3432 - val_acc: 0.9000\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 44s 354ms/step - loss: 0.0530 - acc: 0.9860 - val_loss: 0.3832 - val_acc: 0.9038\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 44s 349ms/step - loss: 0.0597 - acc: 0.9785 - val_loss: 0.4214 - val_acc: 0.8988\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 45s 356ms/step - loss: 0.0361 - acc: 0.9895 - val_loss: 0.4334 - val_acc: 0.9062\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 44s 348ms/step - loss: 0.0328 - acc: 0.9860 - val_loss: 0.3574 - val_acc: 0.9113\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 44s 349ms/step - loss: 0.0360 - acc: 0.9900 - val_loss: 0.3739 - val_acc: 0.9163\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 44s 353ms/step - loss: 0.0390 - acc: 0.9865 - val_loss: 0.4172 - val_acc: 0.9075\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 44s 354ms/step - loss: 0.0353 - acc: 0.9895 - val_loss: 0.5122 - val_acc: 0.9075\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 44s 353ms/step - loss: 0.0556 - acc: 0.9810 - val_loss: 0.3654 - val_acc: 0.9075\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 44s 354ms/step - loss: 0.0251 - acc: 0.9920 - val_loss: 0.3737 - val_acc: 0.9187\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 44s 350ms/step - loss: 0.0517 - acc: 0.9800 - val_loss: 0.4122 - val_acc: 0.9125\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 44s 352ms/step - loss: 0.0202 - acc: 0.9955 - val_loss: 0.4577 - val_acc: 0.9137\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 44s 353ms/step - loss: 0.0145 - acc: 0.9940 - val_loss: 0.5238 - val_acc: 0.9150\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 43s 348ms/step - loss: 0.0213 - acc: 0.9930 - val_loss: 0.4772 - val_acc: 0.9137\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 44s 351ms/step - loss: 0.0264 - acc: 0.9900 - val_loss: 0.4583 - val_acc: 0.9050\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 44s 354ms/step - loss: 0.0237 - acc: 0.9925 - val_loss: 0.4341 - val_acc: 0.9062\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 44s 353ms/step - loss: 0.0178 - acc: 0.9945 - val_loss: 0.4817 - val_acc: 0.9125\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 44s 355ms/step - loss: 0.0160 - acc: 0.9940 - val_loss: 0.6013 - val_acc: 0.9062\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 45s 358ms/step - loss: 0.0190 - acc: 0.9940 - val_loss: 0.4481 - val_acc: 0.9137\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 44s 349ms/step - loss: 0.0188 - acc: 0.9950 - val_loss: 0.4696 - val_acc: 0.9125\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 43s 348ms/step - loss: 0.0113 - acc: 0.9965 - val_loss: 0.5212 - val_acc: 0.9200\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 44s 354ms/step - loss: 0.0236 - acc: 0.9915 - val_loss: 0.5071 - val_acc: 0.9137\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 44s 356ms/step - loss: 0.0170 - acc: 0.9930 - val_loss: 0.5125 - val_acc: 0.9050\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 45s 356ms/step - loss: 0.0094 - acc: 0.9975 - val_loss: 0.5350 - val_acc: 0.9175\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 44s 352ms/step - loss: 0.0108 - acc: 0.9960 - val_loss: 0.7181 - val_acc: 0.9038\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 43s 346ms/step - loss: 0.0241 - acc: 0.9935 - val_loss: 0.4912 - val_acc: 0.9125\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 43s 345ms/step - loss: 0.0147 - acc: 0.9950 - val_loss: 0.4855 - val_acc: 0.9087\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 44s 349ms/step - loss: 0.0134 - acc: 0.9970 - val_loss: 0.5854 - val_acc: 0.9137\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 43s 345ms/step - loss: 0.0031 - acc: 0.9995 - val_loss: 0.5430 - val_acc: 0.9200\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 43s 348ms/step - loss: 0.0064 - acc: 0.9975 - val_loss: 0.5885 - val_acc: 0.9087\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 44s 352ms/step - loss: 0.0091 - acc: 0.9980 - val_loss: 0.4456 - val_acc: 0.9225\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 44s 354ms/step - loss: 0.0055 - acc: 0.9990 - val_loss: 0.5309 - val_acc: 0.9163\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 44s 348ms/step - loss: 0.0093 - acc: 0.9965 - val_loss: 0.4957 - val_acc: 0.9213\n",
      "Epoch 41/50\n",
      "119/125 [===========================>..] - ETA: 0s - loss: 0.0027 - acc: 0.9995"
     ]
    }
   ],
   "source": [
    "'''This script goes along the blog post\n",
    "\"Building powerful image classification models using very little data\"\n",
    "from blog.keras.io.\n",
    "It uses data that can be downloaded at:\n",
    "https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "In our setup, we:\n",
    "- created a data/ folder\n",
    "- created train/ and validation/ subfolders inside data/\n",
    "- created cats/ and dogs/ subfolders inside train/ and validation/\n",
    "- put the cat pictures index 0-999 in data/train/cats\n",
    "- put the cat pictures index 1000-1400 in data/validation/cats\n",
    "- put the dogs pictures index 12500-13499 in data/train/dogs\n",
    "- put the dog pictures index 13500-13900 in data/validation/dogs\n",
    "So that we have 1000 training examples for each class, and 400 validation examples for each class.\n",
    "In summary, this is our directory structure:\n",
    "```\n",
    "data/\n",
    "    train/\n",
    "        dogs/\n",
    "            dog001.jpg\n",
    "            dog002.jpg\n",
    "            ...\n",
    "        cats/\n",
    "            cat001.jpg\n",
    "            cat002.jpg\n",
    "            ...\n",
    "    validation/\n",
    "        dogs/\n",
    "            dog001.jpg\n",
    "            dog002.jpg\n",
    "            ...\n",
    "        cats/\n",
    "            cat001.jpg\n",
    "            cat002.jpg\n",
    "            ...\n",
    "```\n",
    "'''\n",
    "\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense,Input\n",
    "\n",
    "# path to the model weights files.\n",
    "#weights_path = '../keras/examples/vgg16_weights.h5'\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'preprocess/data//train'\n",
    "validation_data_dir = 'preprocess/data//validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "# build the VGG16 network\n",
    "input_tensor = Input(shape=(150,150,3))\n",
    "base_model = applications.VGG16(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
    "  \n",
    "print('Model loaded.')\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "top_model.summary()\n",
    "# note that it is necessary to start with a fully-trained\n",
    "# classifier, including the top classifier,\n",
    "# in order to successfully do fine-tuning\n",
    "top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "# add the model on top of the convolutional base\n",
    "\n",
    "model = Model(input= base_model.input, output= top_model(base_model.output))\n",
    "\n",
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "# fine-tune the model\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=nb_train_samples,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    nb_val_samples=nb_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
